unit CB.AI.Client.OpenAI.Types;

interface

uses
  System.SysUtils, System.JSON.Types,
  CB.AI.Client.Types;

{$M+}
type
  // https://platform.openai.com/docs/api-reference/chat

  TOpenAIFunctionResult = class
  public
    name     : string;
    arguments: string;
  end;

  TOpenAIMessage = class(TAIMessage)
  public
    function_call: TOpenAIFunctionResult;
    destructor Destroy; override;
  end;

  TOpenAIFunction = class
  public
    name       : string;
    description: string;
    parameters : string;
  end;

  TOpenAIRequest = class(TAIRequest)
  public
    max_completion_tokens: integer;
    temperature          : real;
    [JsonName('functions')]
    functions            : TArray<TOpenAIFunction>;
    [JsonName('function_call')]
    function_call        : string;
    destructor Destroy; override;
  end;

  TOpenAIChoice = class
  public
    index        : integer;
    message      : TOpenAIMessage;
    finish_reason: string;
    destructor Destroy; override;
  end;

  TOpenAICompletionTokensDetails = class
  public
    accepted_prediction_tokens: integer; // When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion.
    audio_tokens              : integer; // Audio input tokens generated by the model.
    reasoning_tokens          : integer; // Tokens generated by the model for reasoning.
    rejected_prediction_tokens: integer; // When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion. However, like reasoning tokens, these tokens are still counted in the total completion tokens for purposes of billing, output, and context window limits.
  end;

  TOpenAIPromptTokensDetails = class
  public
    audio_tokens : integer; // Audio input tokens present in the prompt.
    cached_tokens: integer; // Cached tokens present in the prompt.
  end;

  TOpenAIUsage = class
  public
    prompt_tokens    : integer; // Number of tokens in the prompt.
    completion_tokens: integer; // Number of tokens in the generated completion.
    total_tokens     : integer; // Total number of tokens used in the request (prompt + completion).
    completion_tokens_details: TOpenAICompletionTokensDetails;
    prompt_tokens_details    : TOpenAIPromptTokensDetails;
    destructor Destroy; override;
  end;

  TOpenAIResponse = class
  public
    id     : string;
    model  : string;
    choices: TArray<TOpenAIChoice>;
    usage  : TOpenAIUsage;
    destructor Destroy; override;
  end;

  TOpenAIModel = class
  public
    id: string;
  end;

  TOpenAIModels = class
  public
    data: TArray<TOpenAIModel>;
    destructor Destroy; override;
  end;
{$M-}

implementation

{ TOpenAIChoice }

destructor TOpenAIChoice.Destroy;
begin
  message.Free;
  inherited;
end;

{ TOpenAIResponse }

destructor TOpenAIResponse.Destroy;
begin
  for var choice in choices do
    choice.Free;
  usage.Free;
  inherited;
end;

{ TOpenAIUsage }

destructor TOpenAIUsage.Destroy;
begin
  FreeAndNil(completion_tokens_details);
  FreeAndNil(prompt_tokens_details);
  inherited;
end;

{ TOpenAIModels }

destructor TOpenAIModels.Destroy;
begin
  for var model in data do
    model.Free;
  inherited;
end;

{ TOpenAIRequest }

destructor TOpenAIRequest.Destroy;
begin
  for var func in functions do
    func.Free;
  inherited;
end;

{ TOpenAIMessage }

destructor TOpenAIMessage.Destroy;
begin
  FreeAndNil(function_call);
  inherited;
end;

end.
